{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd18bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentin/miniconda3/envs/benchmark-vfm-ss/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datasets.anorak_fewshot import ANORAK_FS\n",
    "from models.protonet_layer import ProtoNet\n",
    "from models.histo_encoder import Uni2Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803a2127",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dbe33e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datasets.anorak_fewshot.ANORAK_FS at 0x7f42cb0f3ee0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up data module to load validation data\n",
    "data_module = ANORAK_FS(\n",
    "    root=\"/home/valentin/workspaces/benchmark-vfm-ss/data/ANORAK\",\n",
    "    devices=1,\n",
    "    num_workers=0,\n",
    "    batch_size=1,\n",
    "    img_size=(448, 448),\n",
    "    num_classes=7,\n",
    "    num_metrics=1\n",
    ")\n",
    "\n",
    "# Setup the data module\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144e3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1a854d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 448\n",
    "PATCH_SIZE = 14\n",
    "encoder = Uni2Encoder(img_size=(IMG_SIZE, IMG_SIZE), patch_size=PATCH_SIZE).to(device)\n",
    "protonet = ProtoNet(img_size=IMG_SIZE, patch_size=PATCH_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a7b7c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'torch.dtype' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprotonet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/benchmark-vfm-ss/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspaces/benchmark-vfm-ss/explo_notebooks/../models/protonet_layer.py:54\u001b[0m, in \u001b[0;36mProtoNet.fit\u001b[0;34m(self, support_dataloader, encoder)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     46\u001b[0m     support_dataloader: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader,\n\u001b[1;32m     47\u001b[0m     encoder: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m     48\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    support_dataloader must output X and y, where y is a one-hot encoding so NxC\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    and X is a feature matrix of shape NxD\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupport_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_prototype(support_dataloader, encoder)\n",
      "File \u001b[0;32m~/workspaces/benchmark-vfm-ss/explo_notebooks/../models/protonet_layer.py:61\u001b[0m, in \u001b[0;36mProtoNet.fit_mean\u001b[0;34m(self, support_dataloader, encoder)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m support_dataloader:\n\u001b[1;32m     60\u001b[0m     imgs, targets \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 61\u001b[0m     targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_per_pixel_targets_semantic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m img, target \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(imgs, targets):\n\u001b[1;32m     64\u001b[0m         crops, target_crops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtile_image(img, target)\n",
      "File \u001b[0;32m~/workspaces/benchmark-vfm-ss/explo_notebooks/../models/protonet_layer.py:205\u001b[0m, in \u001b[0;36mProtoNet.to_per_pixel_targets_semantic\u001b[0;34m(self, targets)\u001b[0m\n\u001b[1;32m    200\u001b[0m per_pixel_targets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets:\n\u001b[1;32m    202\u001b[0m     per_pixel_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull(\n\u001b[1;32m    203\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, target[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]),\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_idx,\n\u001b[0;32m--> 205\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    206\u001b[0m         device\u001b[38;5;241m=\u001b[39mtarget[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    207\u001b[0m     )\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, mask \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(target[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    210\u001b[0m         one_hot_label \u001b[38;5;241m=\u001b[39m one_hot(target[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m][i],\n\u001b[1;32m    211\u001b[0m                                 num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'torch.dtype' object is not callable"
     ]
    }
   ],
   "source": [
    "protonet.fit(train_loader, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3725e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40bd5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark-vfm-ss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
