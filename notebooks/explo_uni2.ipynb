{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "# from huggingface_hub import login\n",
    "\n",
    "# login()  # login with your User Access Token, found at https://huggingface.co/settings/tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85172038",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([0.485, 0.456, 0.406]).reshape(1, -1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pretrained=True needed to load UNI2-h weights (and download weights for the first time)\n",
    "timm_kwargs = {\n",
    "            'img_size': 224, \n",
    "            'patch_size': 14, \n",
    "            'depth': 24,\n",
    "            'num_heads': 24,\n",
    "            'init_values': 1e-5, \n",
    "            'embed_dim': 1536,\n",
    "            'mlp_ratio': 2.66667*2,\n",
    "            'num_classes': 0, \n",
    "            'no_embed_class': True,\n",
    "            'mlp_layer': timm.layers.SwiGLUPacked, \n",
    "            'act_layer': torch.nn.SiLU, \n",
    "            'reg_tokens': 8, \n",
    "            'dynamic_img_size': True\n",
    "        }\n",
    "model = timm.create_model(\"hf-hub:MahmoodLab/UNI2-h\", pretrained=True, **timm_kwargs)\n",
    "transform = create_transform(**resolve_data_config(model.pretrained_cfg, model=model))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f94dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(\"/home/valentin/workspaces/benchmark-vfm-ss/data/ANORAK/image/train001_Da382.png\")\n",
    "# image = transform(image).unsqueeze(dim=0) # Image (torch.Tensor) with shape [1, 3, 224, 224] following image resizing and normalization (ImageNet parameters)\n",
    "image = torch.rand(1, 3, 224, 448)  \n",
    "with torch.inference_mode():\n",
    "    feature_emb = model.forward_features(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_emb.shape  # torch.Size([1, 1536, 16, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.patch_embed.grid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2b6fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb91d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pos_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff05f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.patch_embed(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f5033",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cls_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5288fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_prefix_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3256280",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pos_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7eaddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.patch_embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa916faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.histo.encoder import ViTEncoderPyramidHooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyramid_model = ViTEncoderPyramidHooks(\n",
    "    vit=model,\n",
    "    embed_dim=None,\n",
    "    pyramid_channels=None,\n",
    "    extract_layers=[6, 12, 18, 24],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139edf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    out = pyramid_model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[\"s32\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4055f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b7ba5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70244eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536768ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b250a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark-vfm-ss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
